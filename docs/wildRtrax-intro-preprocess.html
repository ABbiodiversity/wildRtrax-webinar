<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>wildRtrax</title>
    <meta charset="utf-8" />
    <meta name="author" content="Marcus Becker, Alex MacPhail, Elly Knight" />
    <meta name="date" content="2023-10-19" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# wildRtrax
]
.subtitle[
## An R package for environmental sensor data
]
.author[
### Marcus Becker, Alex MacPhail, Elly Knight
]
.date[
### 2023-10-19
]

---




&lt;style type="text/css"&gt;
/* custom.css */
.left-code {
  color: #777;
  width: 90%;
  height: 92%;
  float: left;
}
.left-code-less {
  color: #777;
  width: 90%;
  height: 92%;
  float: left;
}
.right-plot {
  width: 58%;
  float: right;
  padding-left: 1%;
}
.right-plot-more {
  width: 65%;
  float: right;
  padding-left: 1%;
}
.plot-callout {
  height: 225px;
  width: 450px;
  bottom: 5%;
  right: 5%;
  position: absolute;
  padding: 0px;
  z-index: 100;
}
.plot-callout img {
  width: 100%;
  border: 4px solid #23373B;
}
body, h1, h2, h3, h4, h5, h6, p, ul, ol {
  font-family: "Agenda", sans-serif; font-size: 20px /* Replace "Agenda" with the actual font name */
}
.my-one-page-font {
  font-size: 18px;
}
.text-container {
            width: 300px; /* Set the width to your desired value in pixels or other units */
            margin: 0 auto; /* Center the container horizontally */
        }
.main-container { width: 1800px; max-width:2800px;}
.title-slide {
  background-image: url(hex-logo-pipit.png);
  background-position: 100% 0%;
  background-size: 400px;
  padding-left: 100px;  /* delete this for 4:3 aspect ratio */
}

&lt;/style&gt;

# Preface

- We assume you're using an *environmental sensor* such as an **autonomous recording unit (ARU)** or **remote camera**


- We assume you know *WildTrax*

  - A web-enabled portal designed to manage, store, process, share and discover environmental sensor data, developed by the ABMI


- We assume you know *R*

  - A programming language mainly used for statistical computing and data analysis
  
---

# wildRtrax

## What is `wildRtrax`

- An R package for ecologists and advanced users who work with environmental sensors
  
- Contains functions designed to meet most needs in order to organize, analyze and standardize data with the WildTrax infrastructure

## Why did you build `wildRtrax`?

- `wildRtrax` has been built in parallel&lt;sup&gt;1&lt;/sup&gt; with WildTrax to provide additional analytics and functionalities

- By outlining a standardized and harmonized procedure for data intake, quality control, processing and verification of environmental sensor data,`wildRtrax` and WildTrax hope to provide open work flows for environmental sensors to help answer biological and ecological questions

---

## Who is `wildRtrax`?

- Us

- And YOU! (you'll learn how to make a pull request soon)

---

# Today's Agenda

- Installing the package
- Pre-processing acoustic data
- Downloading data from WildTrax
- Wrangling camera and acoustic data for analysis
- Contributing to package and submitting issues

---

&lt;img src="drake.png" style="width:60%;" align="center"&gt;

---

# Installing the package

`remotes::install_github('ABbiodiversity/wildRtrax')`

Interested in recent fixes? Download the development branch instead:

`remotes::install_github('ABbiodiversity/wildRtrax@development')`

---

class: my-one-page-font

# Scanning acoustic data




```r
# Load the package
library(wildRtrax)

# Plan futures
plan(strategy = multisession)

# Scan data
files &lt;- wt_audio_scanner(path = ".", file_type = "wav", extra_cols = T)
```


```
## # A tibble: 1,166 × 13
##    file_path     size_Mb file_name location recording_date_time file_type julian
##    &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;    &lt;dttm&gt;              &lt;chr&gt;      &lt;dbl&gt;
##  1 /volumes/bud…    4.36 339-NW_2… 339-NW   2022-11-17 15:28:51 wav          321
##  2 /volumes/bud…  106.   339-NW_2… 339-NW   2023-03-01 00:00:00 wav           60
##  3 /volumes/bud…   31.8  339-NW_2… 339-NW   2023-03-01 02:00:00 wav           60
##  4 /volumes/bud…  106.   339-NW_2… 339-NW   2023-03-01 09:00:00 wav           60
##  5 /volumes/bud…   31.8  339-NW_2… 339-NW   2023-03-01 10:30:00 wav           60
##  6 /volumes/bud…   31.8  339-NW_2… 339-NW   2023-03-01 12:00:00 wav           60
##  7 /volumes/bud…   31.8  339-NW_2… 339-NW   2023-03-01 15:00:00 wav           60
##  8 /volumes/bud…   31.8  339-NW_2… 339-NW   2023-03-01 18:16:00 wav           60
##  9 /volumes/bud…   31.8  339-NW_2… 339-NW   2023-03-01 20:16:00 wav           60
## 10 /volumes/bud…  106.   339-NW_2… 339-NW   2023-03-02 00:00:00 wav           61
## # ℹ 1,156 more rows
## # ℹ 6 more variables: year &lt;dbl&gt;, gps_enabled &lt;lgl&gt;, time_index &lt;int&gt;,
## #   length_seconds &lt;dbl&gt;, sample_rate &lt;dbl&gt;, n_channels &lt;dbl&gt;
```

---

# Scanning acoustic data


```r
files |&gt;
  names()
```

```
##  [1] "file_path"           "size_Mb"             "file_name"          
##  [4] "location"            "recording_date_time" "file_type"          
##  [7] "julian"              "year"                "gps_enabled"        
## [10] "time_index"          "length_seconds"      "sample_rate"        
## [13] "n_channels"
```

- `location` (where the recording was taken)
- `recording_date_time` (when the recording was taken)

**`339-NW_20230528_071000.wav`**

You can also add arguments `extra_cols` (sample_rate, length_seconds, n_channels) or `tz` if you want to assign a timezone to the recordings.

`wt_audio_scanner(path = '.', file_type = 'wav', extra_cols = T, tz = 'US/Mountain')`

---

# Filtering files


```r
files |&gt;
  mutate(hour = lubridate::hour(recording_date_time)) |&gt;
  filter(julian %in% c(140:150),
         hour %in% c(4:8))
```

```
## # A tibble: 22 × 14
##    file_path     size_Mb file_name location recording_date_time file_type julian
##    &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;    &lt;dttm&gt;              &lt;chr&gt;      &lt;dbl&gt;
##  1 /volumes/bud…   106.  339-NW_2… 339-NW   2023-05-20 05:57:00 wav          140
##  2 /volumes/bud…    31.8 339-NW_2… 339-NW   2023-05-20 07:27:00 wav          140
##  3 /volumes/bud…   106.  339-NW_2… 339-NW   2023-05-21 05:55:00 wav          141
##  4 /volumes/bud…    31.8 339-NW_2… 339-NW   2023-05-21 07:25:00 wav          141
##  5 /volumes/bud…   106.  339-NW_2… 339-NW   2023-05-22 05:54:00 wav          142
##  6 /volumes/bud…    31.8 339-NW_2… 339-NW   2023-05-22 07:24:00 wav          142
##  7 /volumes/bud…   106.  339-NW_2… 339-NW   2023-05-23 05:53:00 wav          143
##  8 /volumes/bud…    31.8 339-NW_2… 339-NW   2023-05-23 07:23:00 wav          143
##  9 /volumes/bud…   106.  339-NW_2… 339-NW   2023-05-24 05:51:00 wav          144
## 10 /volumes/bud…    31.8 339-NW_2… 339-NW   2023-05-24 07:21:00 wav          144
## # ℹ 12 more rows
## # ℹ 7 more variables: year &lt;dbl&gt;, gps_enabled &lt;lgl&gt;, time_index &lt;int&gt;,
## #   length_seconds &lt;dbl&gt;, sample_rate &lt;dbl&gt;, n_channels &lt;dbl&gt;, hour &lt;int&gt;
```

---

class: my-one-page-font

# Generating acoustic indices and LDFCs


```r
# Use the files tibble to execute AP on them
wt_run_ap(x = files, output_dir = 'ap_outputs', path_to_ap = '/where/you/store/AP')

results &lt;- wt_glean_ap(files, input_dir = ".../ap_outputs", purpose = "biotic")

# The indices
results[[2]]
```

&lt;img src="339-nw-indices.png", width="50%;"&gt;

---

## Long-duration false-colour spectrogram


```r
results[[3]]
```

&lt;img src="339-nw.png"&gt;

---

## Manipulating the results


```r
wt_glean_ap(files %&gt;%
              mutate(hour = lubridate::hour(recording_date_time)) %&gt;%
              filter(hour %in% c(0:3,21:23)), 
            input_dir = "../ap_outputs", purpose = "biotic")
```

&lt;img src="339-nw-noctural.png"&gt;

---

# Creating tasks and tags

## Upload recordings and generate tasks simulatenously

+ Go to a Project and select Manage &gt; Upload Recordings to Project


```r
# Choose recordings for the ABMI Stratified Design for Ecosystem Health
tasks &lt;- files |&gt;
  inner_join(abmi_blocks, by = c("julian" = "julian", "time_index" = "time_index")) |&gt;
  drop_na(blocks) |&gt;
  group_by(location, blocks) |&gt;
  sample_n(1, replace = F) |&gt;
  ungroup() |&gt;
  map(.x = .$file_path, .f = ~file.copy(.x, to = "/my/selected/files"))
```

---

# Creating tasks and tags

## Upload recordings and create tasks later

+ Go to the Organization &gt; Recordings &gt; Manage &gt; Upload Recordings and create tasks later using `wt_make_aru_tasks()`


```r
my_tasks &lt;- wt_make_aru_tasks(
  tasks %&gt;% 
    select(-c(blocks:recs)),
  output = NULL,
  task_method = "1SPT",
  task_length = 180
)

my_tasks
```

---

# Creating tasks and tags

.left-column[

## From Songscope


```r
# Generate a tag csv to upload to WildTrax 
wt_songscope_tags(
  input,
  output = "env",
  my_output_file = NULL,
  species_code = "CONI",
  vocalization_type = "CALL",
  score_filter = 50,
  method = "USPM",
  task_length = 180
)
```
]

.right-column[

## From Kaleidoscope


```r
# Generate a tag csv to upload to WildTrax 
wt_kaleidoscope_tags(input = "kaleidoscope_output.txt",
                     output = "my_bat_tags.csv"
                     freq_bump = 20000)
```

]
---

# Another day perhaps...

- `wt_signal_level()` detects signals in audio based on amplitude thresholds
- `wt_chop()` divides a large audio file into shorter segments
- `wt_location_distances()` takes input latitude and longitudes and computes the distances between each set of valid points

---

## Handing it off to Marcus!

&lt;img src="handingitoff.jpg" width=30% align=middle&gt;
---



    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"hightlightSpans": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
